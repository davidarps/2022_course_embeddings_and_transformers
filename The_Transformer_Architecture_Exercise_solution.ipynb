{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The Transformer Architecture_Exercise_solution.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoz4lRrWK5Vo"
      },
      "outputs": [],
      "source": [
        "#!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip -q install bertviz\n"
      ],
      "metadata": {
        "id": "vLbrCjyULVKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Scaled dot-product attention"
      ],
      "metadata": {
        "id": "hv-1kJCAL0rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from bertviz.transformers_neuron_view import BertModel\n",
        "from bertviz.neuron_view import show"
      ],
      "metadata": {
        "id": "wrWdQv1PLfxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"bert-base-uncased\""
      ],
      "metadata": {
        "id": "4gJbJVKWMGU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "PKreoKUPMvJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "TEBQbiUZMzEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"time flies like an arrow\""
      ],
      "metadata": {
        "id": "B_6Lx_f2M3Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(model, \"bert\", tokenizer, text, display_mode=\"dark\", layer=0, head=8)"
      ],
      "metadata": {
        "id": "Oj6P7a3_Nctt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question \n",
        "What can you see from the visualisation ? Can you expalain that ?\n",
        "### Answer\n",
        "*   The values of the query and key vectors are represented as vertical bands\n",
        "*   The intensity of each band corresponds to the magnitude.\n",
        "*   The connecting lines are weighted according to the attention between the tokens\n",
        "*   The query vector for “flies” has the strongest overlap with the key vector for “arrow”."
      ],
      "metadata": {
        "id": "Hxpla8iaOPSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Understanding Queries, Keys, and Values"
      ],
      "metadata": {
        "id": "yPrM-KxZP06I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q = What is the intuition behind using the Keys, and Values, Query ?  can you give an exampe ? \n",
        "A = The notion of query, key, and value vectors may seem a bit difficult to understand the first time you encounter them. \n",
        "Imagine that you’re at the supermarket buying all the ingredients you need for your dinner. You have the dish’s recipe, and each of the required ingredients can be thought of as a **query**. \n",
        "As you scan the shelves, you look at the labels (**keys**) and check whether they match an ingredient on your list (**similarity function**). If you have a match, then you take the item (**value**) from the shelf. \n"
      ],
      "metadata": {
        "id": "Swn4ofRyQoH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try to tokenize the text, and extract the input IDs\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "inputs.input_ids\n"
      ],
      "metadata": {
        "id": "zZ1ETbXPRP0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## try to get the embedding \n",
        "from torch import nn\n",
        "from transformers import AutoConfig\n",
        "config = AutoConfig.from_pretrained(model_ckpt)\n",
        "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "token_emb"
      ],
      "metadata": {
        "id": "c8KNOwJoUvx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## How can you get the embedding for your input sentence ? what is the size of your representation\n",
        "#[batch_size, seq_len, hidden_dim]\n",
        "inputs_embeds = token_emb(inputs.input_ids)\n",
        "inputs_embeds.size()\n"
      ],
      "metadata": {
        "id": "4EJILrfiWFd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the query, key, and value vectors and calculate the attention scores \n",
        "#using the dot product as the similarity function:\n",
        "\n",
        "import torch\n",
        "from math import sqrt\n",
        "query = key = value = inputs_embeds"
      ],
      "metadata": {
        "id": "Zb4zuK40W7Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## How can you get the dimesion of the key ?  \n",
        "## refer to the slides\n",
        "dim_k = key.size(-1)\n",
        "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
        "scores.size()\n",
        "## created a 5×5 matrix of attention scores per sample in the batch"
      ],
      "metadata": {
        "id": "LPOfTiksYq7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## How can you apply  apply the softmax to these matrices\n",
        "import torch.nn.functional as F\n",
        "\n",
        "weights = F.softmax(scores, dim=-1)\n",
        "weights.sum(dim=-1)"
      ],
      "metadata": {
        "id": "0m1aA_4DYxwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## multiply the attention weights by the values\n",
        "attn_outputs = torch.bmm(weights, value)\n",
        "attn_outputs.shape"
      ],
      "metadata": {
        "id": "i8SaoyE6dBtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## write a function to calculate the self attention\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    return torch.bmm(weights, value)"
      ],
      "metadata": {
        "id": "lGQWSzZydZhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VaNaYYA8ddU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot y=sin(2/10000^(2*x/512))\n"
      ],
      "metadata": {
        "id": "WIu3jk3ChPmV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}